{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57d9a13-a717-43ca-89d9-ccd52d5eaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is for model training two times : 1.train with sparsity  2.train after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf6162a-4582-4df1-b4fb-3100d2a2bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful package\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import models\n",
    "from torchinfo import summary\n",
    "from utils import progress_bar\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f40f2fb-68b6-43a9-8da4-a7dc276ecb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# set up device \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6871a1-26c5-4014-ab32-a178b28575d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14c7de1-06f8-432c-a277-d0ad43d7b69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "11105866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "resnet                                   [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 64, 32, 32]           1,728\n",
       "├─Sequential: 1-2                        [1, 64, 32, 32]           --\n",
       "│    └─FusionBlock: 2-1                  [1, 64, 32, 32]           --\n",
       "│    │    └─Sequential: 3-1              [1, 64, 32, 32]           4,928\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 32, 32]           --\n",
       "│    │    └─Sequential: 3-4              [1, 64, 32, 32]           4,928\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 32, 32]           --\n",
       "│    └─FusionBlock: 2-2                  [1, 64, 32, 32]           --\n",
       "│    │    └─Sequential: 3-7              [1, 64, 32, 32]           4,928\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 32, 32]           --\n",
       "│    │    └─Sequential: 3-10             [1, 64, 32, 32]           4,928\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 32, 32]           128\n",
       "│    │    └─Sequential: 3-12             [1, 64, 32, 32]           102,528\n",
       "│    │    └─ReLU: 3-13                   [1, 64, 32, 32]           --\n",
       "├─Sequential: 1-3                        [1, 128, 16, 16]          --\n",
       "│    └─FusionBlock: 2-3                  [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-14             [1, 128, 16, 16]          9,216\n",
       "│    │    └─BatchNorm2d: 3-15            [1, 128, 16, 16]          256\n",
       "│    │    └─ReLU: 3-16                   [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-17             [1, 128, 16, 16]          18,048\n",
       "│    │    └─BatchNorm2d: 3-18            [1, 128, 16, 16]          256\n",
       "│    │    └─Sequential: 3-19             [1, 128, 16, 16]          8,192\n",
       "│    │    └─ReLU: 3-20                   [1, 128, 16, 16]          --\n",
       "│    └─FusionBlock: 2-4                  [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-21             [1, 128, 16, 16]          18,048\n",
       "│    │    └─BatchNorm2d: 3-22            [1, 128, 16, 16]          256\n",
       "│    │    └─ReLU: 3-23                   [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-24             [1, 128, 16, 16]          18,048\n",
       "│    │    └─BatchNorm2d: 3-25            [1, 128, 16, 16]          256\n",
       "│    │    └─Sequential: 3-26             [1, 128, 16, 16]          409,856\n",
       "│    │    └─ReLU: 3-27                   [1, 128, 16, 16]          --\n",
       "├─Sequential: 1-4                        [1, 256, 8, 8]            --\n",
       "│    └─BasicBlock: 2-5                   [1, 256, 8, 8]            --\n",
       "│    │    └─BatchNorm2d: 3-28            [1, 128, 16, 16]          256\n",
       "│    │    └─channel_selection: 3-29      [1, 128, 16, 16]          128\n",
       "│    │    └─ReLU: 3-30                   [1, 128, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-31                 [1, 256, 8, 8]            294,912\n",
       "│    │    └─BatchNorm2d: 3-32            [1, 256, 8, 8]            512\n",
       "│    │    └─ReLU: 3-33                   [1, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-34                 [1, 256, 8, 8]            589,824\n",
       "│    │    └─Sequential: 3-35             [1, 256, 8, 8]            32,768\n",
       "│    └─BasicBlock: 2-6                   [1, 256, 8, 8]            --\n",
       "│    │    └─BatchNorm2d: 3-36            [1, 256, 8, 8]            512\n",
       "│    │    └─channel_selection: 3-37      [1, 256, 8, 8]            256\n",
       "│    │    └─ReLU: 3-38                   [1, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-39                 [1, 256, 8, 8]            589,824\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 256, 8, 8]            512\n",
       "│    │    └─ReLU: 3-41                   [1, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-42                 [1, 256, 8, 8]            589,824\n",
       "├─Sequential: 1-5                        [1, 512, 4, 4]            --\n",
       "│    └─BasicBlock: 2-7                   [1, 512, 4, 4]            --\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 256, 8, 8]            512\n",
       "│    │    └─channel_selection: 3-44      [1, 256, 8, 8]            256\n",
       "│    │    └─ReLU: 3-45                   [1, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-46                 [1, 512, 4, 4]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 512, 4, 4]            1,024\n",
       "│    │    └─ReLU: 3-48                   [1, 512, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-49                 [1, 512, 4, 4]            2,359,296\n",
       "│    │    └─Sequential: 3-50             [1, 512, 4, 4]            131,072\n",
       "│    └─BasicBlock: 2-8                   [1, 512, 4, 4]            --\n",
       "│    │    └─BatchNorm2d: 3-51            [1, 512, 4, 4]            1,024\n",
       "│    │    └─channel_selection: 3-52      [1, 512, 4, 4]            512\n",
       "│    │    └─ReLU: 3-53                   [1, 512, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-54                 [1, 512, 4, 4]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-55            [1, 512, 4, 4]            1,024\n",
       "│    │    └─ReLU: 3-56                   [1, 512, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-57                 [1, 512, 4, 4]            2,359,296\n",
       "├─BatchNorm2d: 1-6                       [1, 512, 4, 4]            1,024\n",
       "├─channel_selection: 1-7                 [1, 512, 4, 4]            512\n",
       "├─ReLU: 1-8                              [1, 512, 4, 4]            --\n",
       "├─AvgPool2d: 1-9                         [1, 512, 1, 1]            --\n",
       "├─Linear: 1-10                           [1, 10]                   5,130\n",
       "==========================================================================================\n",
       "Total params: 11,105,866\n",
       "Trainable params: 11,105,866\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 517.65\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 17.50\n",
       "Params size (MB): 44.42\n",
       "Estimated Total Size (MB): 61.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model for baseline\n",
    "print('==> Building model..')\n",
    "\n",
    "model = models.resnet()\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(params)\n",
    "summary(model, input_size=(1,3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee0d45a-219e-4e68-8256-1df8d78dfb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20669bc5-a259-406c-9423-ac4552e8d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional subgradient descent on the sparsity-induced penalty term\n",
    "\n",
    "# trade-off factors \n",
    "s  = 0.00001\n",
    "\n",
    "# add new item on grad computation\n",
    "def updateBN():\n",
    "    for name,m in model.named_modules():\n",
    "        if isinstance(m, nn.BatchNorm2d) and 'fusion' not in name:\n",
    "            m.weight.grad.data.add_(s*torch.sign(m.weight.data))  # L1 regularization\n",
    "\n",
    "#training function\n",
    "def train(epoch,train_loss_list,train_acc_list):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_loss +=loss.item()\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # calculate the gradient for bn scaling factors\n",
    "        updateBN()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()/len(data)))\n",
    "                  \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    train_acc_list.append(train_acc_list)\n",
    "    \n",
    "    print('\\nTraining Set: Average loss: {:.4f},Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            train_loss, correct, len(train_loader.dataset),100.*train_acc))\n",
    "\n",
    "# test function\n",
    "def test(test_loss_list):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() # sum up batch loss\n",
    "\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_acc = correct / float(len(test_loader.dataset))\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100. * test_acc))\n",
    "        \n",
    "        return test_acc\n",
    "\n",
    "def save_checkpoint(state, is_best, filepath):\n",
    "    torch.save(state, os.path.join(filepath, 'baseline.pth.tar'))\n",
    "    if is_best:\n",
    "        print('\\n!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \\n')\n",
    "        shutil.copyfile(os.path.join(filepath, 'baseline.pth.tar'), os.path.join(filepath, 'baseline_model_best.pth.tar'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0282b02d-038a-4ab3-80f6-031385b17ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.025190\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.013627\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.013440\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.011692\n",
      "\n",
      "Training Set: Average loss: 0.0134,Accuracy: 18523/50000 (37.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4675/10000 (46.8%)\n",
      "\n",
      "One epoch time cost: 45.749 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.011130\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.010952\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.011579\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.009966\n",
      "\n",
      "Training Set: Average loss: 0.0105,Accuracy: 25566/50000 (51.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5642/10000 (56.4%)\n",
      "\n",
      "One epoch time cost: 45.403 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.009641\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.008598\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.008817\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.008621\n",
      "\n",
      "Training Set: Average loss: 0.0088,Accuracy: 29986/50000 (60.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6286/10000 (62.9%)\n",
      "\n",
      "One epoch time cost: 45.914 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.006321\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.008730\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.007482\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.007475\n",
      "\n",
      "Training Set: Average loss: 0.0076,Accuracy: 32936/50000 (65.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 6778/10000 (67.8%)\n",
      "\n",
      "One epoch time cost: 46.270 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.007134\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.006001\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.007406\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.004843\n",
      "\n",
      "Training Set: Average loss: 0.0065,Accuracy: 35415/50000 (70.8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7301/10000 (73.0%)\n",
      "\n",
      "One epoch time cost: 46.295 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.005665\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.005624\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.004896\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.004623\n",
      "\n",
      "Training Set: Average loss: 0.0054,Accuracy: 37924/50000 (75.8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 7731/10000 (77.3%)\n",
      "\n",
      "One epoch time cost: 46.842 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.005243\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.003993\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.005225\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.003509\n",
      "\n",
      "Training Set: Average loss: 0.0046,Accuracy: 39851/50000 (79.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0060, Accuracy: 7965/10000 (79.7%)\n",
      "\n",
      "One epoch time cost: 46.547 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.005438\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.003909\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.004045\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.004005\n",
      "\n",
      "Training Set: Average loss: 0.0040,Accuracy: 41121/50000 (82.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 8241/10000 (82.4%)\n",
      "\n",
      "One epoch time cost: 47.001 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.004134\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.003301\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.004640\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.002693\n",
      "\n",
      "Training Set: Average loss: 0.0035,Accuracy: 42164/50000 (84.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0051, Accuracy: 8264/10000 (82.6%)\n",
      "\n",
      "One epoch time cost: 46.006 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.003249\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.003057\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.002295\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.002982\n",
      "\n",
      "Training Set: Average loss: 0.0032,Accuracy: 42991/50000 (86.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 8405/10000 (84.1%)\n",
      "\n",
      "One epoch time cost: 44.855 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.003300\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.003327\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.002827\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.002514\n",
      "\n",
      "Training Set: Average loss: 0.0029,Accuracy: 43522/50000 (87.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 8465/10000 (84.7%)\n",
      "\n",
      "One epoch time cost: 44.716 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.003085\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.002192\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.002634\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.002337\n",
      "\n",
      "Training Set: Average loss: 0.0027,Accuracy: 44072/50000 (88.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 8547/10000 (85.5%)\n",
      "\n",
      "One epoch time cost: 44.967 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.003368\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.002485\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.004012\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.002280\n",
      "\n",
      "Training Set: Average loss: 0.0025,Accuracy: 44550/50000 (89.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0042, Accuracy: 8635/10000 (86.3%)\n",
      "\n",
      "One epoch time cost: 44.945 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.002203\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.002625\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.002007\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.001869\n",
      "\n",
      "Training Set: Average loss: 0.0023,Accuracy: 45017/50000 (90.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 8672/10000 (86.7%)\n",
      "\n",
      "One epoch time cost: 45.175 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.001853\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.002612\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.002331\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.001881\n",
      "\n",
      "Training Set: Average loss: 0.0022,Accuracy: 45279/50000 (90.6%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 8683/10000 (86.8%)\n",
      "\n",
      "One epoch time cost: 45.805 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.002204\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.001703\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.001744\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.001875\n",
      "\n",
      "Training Set: Average loss: 0.0018,Accuracy: 46078/50000 (92.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 8732/10000 (87.3%)\n",
      "\n",
      "One epoch time cost: 46.561 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.001913\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.002007\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.001422\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.001372\n",
      "\n",
      "Training Set: Average loss: 0.0017,Accuracy: 46267/50000 (92.5%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8767/10000 (87.7%)\n",
      "\n",
      "One epoch time cost: 47.378 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.001552\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.001372\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.001557\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.001919\n",
      "\n",
      "Training Set: Average loss: 0.0017,Accuracy: 46368/50000 (92.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8768/10000 (87.7%)\n",
      "\n",
      "One epoch time cost: 47.621 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.001517\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.001952\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.001196\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.002088\n",
      "\n",
      "Training Set: Average loss: 0.0017,Accuracy: 46370/50000 (92.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8795/10000 (87.9%)\n",
      "\n",
      "One epoch time cost: 47.396 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.001355\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.001240\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.001961\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.001316\n",
      "\n",
      "Training Set: Average loss: 0.0016,Accuracy: 46343/50000 (92.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8778/10000 (87.8%)\n",
      "\n",
      "One epoch time cost: 47.961 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 20 [0/50000 (0.0%)]\tLoss: 0.002164\n",
      "Train Epoch: 20 [12800/50000 (25.6%)]\tLoss: 0.001378\n",
      "Train Epoch: 20 [25600/50000 (51.2%)]\tLoss: 0.002279\n",
      "Train Epoch: 20 [38400/50000 (76.7%)]\tLoss: 0.001743\n",
      "\n",
      "Training Set: Average loss: 0.0016,Accuracy: 46499/50000 (93.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8799/10000 (88.0%)\n",
      "\n",
      "One epoch time cost: 47.486 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 21 [0/50000 (0.0%)]\tLoss: 0.001775\n",
      "Train Epoch: 21 [12800/50000 (25.6%)]\tLoss: 0.001701\n",
      "Train Epoch: 21 [25600/50000 (51.2%)]\tLoss: 0.001805\n",
      "Train Epoch: 21 [38400/50000 (76.7%)]\tLoss: 0.001263\n",
      "\n",
      "Training Set: Average loss: 0.0016,Accuracy: 46542/50000 (93.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8810/10000 (88.1%)\n",
      "\n",
      "One epoch time cost: 47.972 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 22 [0/50000 (0.0%)]\tLoss: 0.001019\n",
      "Train Epoch: 22 [12800/50000 (25.6%)]\tLoss: 0.002249\n",
      "Train Epoch: 22 [25600/50000 (51.2%)]\tLoss: 0.001593\n",
      "Train Epoch: 22 [38400/50000 (76.7%)]\tLoss: 0.001790\n",
      "\n",
      "Training Set: Average loss: 0.0016,Accuracy: 46532/50000 (93.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8798/10000 (88.0%)\n",
      "\n",
      "One epoch time cost: 47.549 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 23 [0/50000 (0.0%)]\tLoss: 0.000978\n",
      "Train Epoch: 23 [12800/50000 (25.6%)]\tLoss: 0.002407\n",
      "Train Epoch: 23 [25600/50000 (51.2%)]\tLoss: 0.002233\n",
      "Train Epoch: 23 [38400/50000 (76.7%)]\tLoss: 0.001740\n",
      "\n",
      "Training Set: Average loss: 0.0016,Accuracy: 46540/50000 (93.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8802/10000 (88.0%)\n",
      "\n",
      "One epoch time cost: 47.951 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 24 [0/50000 (0.0%)]\tLoss: 0.001397\n",
      "Train Epoch: 24 [12800/50000 (25.6%)]\tLoss: 0.001333\n",
      "Train Epoch: 24 [25600/50000 (51.2%)]\tLoss: 0.001626\n",
      "Train Epoch: 24 [38400/50000 (76.7%)]\tLoss: 0.001301\n",
      "\n",
      "Training Set: Average loss: 0.0015,Accuracy: 46643/50000 (93.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8790/10000 (87.9%)\n",
      "\n",
      "One epoch time cost: 47.740 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 25 [0/50000 (0.0%)]\tLoss: 0.001406\n",
      "Train Epoch: 25 [12800/50000 (25.6%)]\tLoss: 0.001717\n",
      "Train Epoch: 25 [25600/50000 (51.2%)]\tLoss: 0.001002\n",
      "Train Epoch: 25 [38400/50000 (76.7%)]\tLoss: 0.001442\n",
      "\n",
      "Training Set: Average loss: 0.0015,Accuracy: 46714/50000 (93.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8788/10000 (87.9%)\n",
      "\n",
      "One epoch time cost: 47.823 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 26 [0/50000 (0.0%)]\tLoss: 0.001286\n",
      "Train Epoch: 26 [12800/50000 (25.6%)]\tLoss: 0.001418\n",
      "Train Epoch: 26 [25600/50000 (51.2%)]\tLoss: 0.001367\n",
      "Train Epoch: 26 [38400/50000 (76.7%)]\tLoss: 0.002467\n",
      "\n",
      "Training Set: Average loss: 0.0015,Accuracy: 46687/50000 (93.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8804/10000 (88.0%)\n",
      "\n",
      "One epoch time cost: 47.915 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 27 [0/50000 (0.0%)]\tLoss: 0.001881\n",
      "Train Epoch: 27 [12800/50000 (25.6%)]\tLoss: 0.001295\n",
      "Train Epoch: 27 [25600/50000 (51.2%)]\tLoss: 0.000974\n",
      "Train Epoch: 27 [38400/50000 (76.7%)]\tLoss: 0.001061\n",
      "\n",
      "Training Set: Average loss: 0.0015,Accuracy: 46798/50000 (93.6%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8821/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.662 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 28 [0/50000 (0.0%)]\tLoss: 0.002041\n",
      "Train Epoch: 28 [12800/50000 (25.6%)]\tLoss: 0.001620\n",
      "Train Epoch: 28 [25600/50000 (51.2%)]\tLoss: 0.000844\n",
      "Train Epoch: 28 [38400/50000 (76.7%)]\tLoss: 0.001379\n",
      "\n",
      "Training Set: Average loss: 0.0015,Accuracy: 46872/50000 (93.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8832/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 48.050 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 29 [0/50000 (0.0%)]\tLoss: 0.001908\n",
      "Train Epoch: 29 [12800/50000 (25.6%)]\tLoss: 0.001051\n",
      "Train Epoch: 29 [25600/50000 (51.2%)]\tLoss: 0.001259\n",
      "Train Epoch: 29 [38400/50000 (76.7%)]\tLoss: 0.001170\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 46834/50000 (93.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8810/10000 (88.1%)\n",
      "\n",
      "One epoch time cost: 47.654 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 30 [0/50000 (0.0%)]\tLoss: 0.000999\n",
      "Train Epoch: 30 [12800/50000 (25.6%)]\tLoss: 0.001800\n",
      "Train Epoch: 30 [25600/50000 (51.2%)]\tLoss: 0.001375\n",
      "Train Epoch: 30 [38400/50000 (76.7%)]\tLoss: 0.001682\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 46931/50000 (93.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8828/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 48.143 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 31 [0/50000 (0.0%)]\tLoss: 0.001541\n",
      "Train Epoch: 31 [12800/50000 (25.6%)]\tLoss: 0.001453\n",
      "Train Epoch: 31 [25600/50000 (51.2%)]\tLoss: 0.001488\n",
      "Train Epoch: 31 [38400/50000 (76.7%)]\tLoss: 0.001531\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 46891/50000 (93.8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8821/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.644 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 32 [0/50000 (0.0%)]\tLoss: 0.000898\n",
      "Train Epoch: 32 [12800/50000 (25.6%)]\tLoss: 0.001311\n",
      "Train Epoch: 32 [25600/50000 (51.2%)]\tLoss: 0.001163\n",
      "Train Epoch: 32 [38400/50000 (76.7%)]\tLoss: 0.001122\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 46944/50000 (93.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8808/10000 (88.1%)\n",
      "\n",
      "One epoch time cost: 47.038 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 33 [0/50000 (0.0%)]\tLoss: 0.001295\n",
      "Train Epoch: 33 [12800/50000 (25.6%)]\tLoss: 0.001125\n",
      "Train Epoch: 33 [25600/50000 (51.2%)]\tLoss: 0.001935\n",
      "Train Epoch: 33 [38400/50000 (76.7%)]\tLoss: 0.001152\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 46968/50000 (93.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8828/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 45.201 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 34 [0/50000 (0.0%)]\tLoss: 0.001451\n",
      "Train Epoch: 34 [12800/50000 (25.6%)]\tLoss: 0.001318\n",
      "Train Epoch: 34 [25600/50000 (51.2%)]\tLoss: 0.001677\n",
      "Train Epoch: 34 [38400/50000 (76.7%)]\tLoss: 0.001912\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47036/50000 (94.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8819/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 44.995 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 35 [0/50000 (0.0%)]\tLoss: 0.001543\n",
      "Train Epoch: 35 [12800/50000 (25.6%)]\tLoss: 0.001139\n",
      "Train Epoch: 35 [25600/50000 (51.2%)]\tLoss: 0.001525\n",
      "Train Epoch: 35 [38400/50000 (76.7%)]\tLoss: 0.001127\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 46962/50000 (93.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8831/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 44.956 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 36 [0/50000 (0.0%)]\tLoss: 0.001329\n",
      "Train Epoch: 36 [12800/50000 (25.6%)]\tLoss: 0.001322\n",
      "Train Epoch: 36 [25600/50000 (51.2%)]\tLoss: 0.000644\n",
      "Train Epoch: 36 [38400/50000 (76.7%)]\tLoss: 0.001311\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 47073/50000 (94.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8828/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 45.081 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 37 [0/50000 (0.0%)]\tLoss: 0.001170\n",
      "Train Epoch: 37 [12800/50000 (25.6%)]\tLoss: 0.001108\n",
      "Train Epoch: 37 [25600/50000 (51.2%)]\tLoss: 0.001272\n",
      "Train Epoch: 37 [38400/50000 (76.7%)]\tLoss: 0.001161\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47073/50000 (94.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8824/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 45.374 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 38 [0/50000 (0.0%)]\tLoss: 0.001166\n",
      "Train Epoch: 38 [12800/50000 (25.6%)]\tLoss: 0.001564\n",
      "Train Epoch: 38 [25600/50000 (51.2%)]\tLoss: 0.001366\n",
      "Train Epoch: 38 [38400/50000 (76.7%)]\tLoss: 0.001324\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47102/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8819/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 45.902 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 39 [0/50000 (0.0%)]\tLoss: 0.001934\n",
      "Train Epoch: 39 [12800/50000 (25.6%)]\tLoss: 0.001238\n",
      "Train Epoch: 39 [25600/50000 (51.2%)]\tLoss: 0.001406\n",
      "Train Epoch: 39 [38400/50000 (76.7%)]\tLoss: 0.001333\n",
      "\n",
      "Training Set: Average loss: 0.0014,Accuracy: 46997/50000 (94.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8823/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 46.745 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 40 [0/50000 (0.0%)]\tLoss: 0.001441\n",
      "Train Epoch: 40 [12800/50000 (25.6%)]\tLoss: 0.001022\n",
      "Train Epoch: 40 [25600/50000 (51.2%)]\tLoss: 0.001066\n",
      "Train Epoch: 40 [38400/50000 (76.7%)]\tLoss: 0.002136\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47128/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8842/10000 (88.4%)\n",
      "\n",
      "One epoch time cost: 47.700 s \n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!! NEW BEST ACC !!!!!!!!!!!!! \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 41 [0/50000 (0.0%)]\tLoss: 0.001074\n",
      "Train Epoch: 41 [12800/50000 (25.6%)]\tLoss: 0.001555\n",
      "Train Epoch: 41 [25600/50000 (51.2%)]\tLoss: 0.001643\n",
      "Train Epoch: 41 [38400/50000 (76.7%)]\tLoss: 0.001139\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47097/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8820/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.589 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 42 [0/50000 (0.0%)]\tLoss: 0.001761\n",
      "Train Epoch: 42 [12800/50000 (25.6%)]\tLoss: 0.001700\n",
      "Train Epoch: 42 [25600/50000 (51.2%)]\tLoss: 0.000984\n",
      "Train Epoch: 42 [38400/50000 (76.7%)]\tLoss: 0.000689\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47125/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8821/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.695 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 43 [0/50000 (0.0%)]\tLoss: 0.001302\n",
      "Train Epoch: 43 [12800/50000 (25.6%)]\tLoss: 0.002052\n",
      "Train Epoch: 43 [25600/50000 (51.2%)]\tLoss: 0.001605\n",
      "Train Epoch: 43 [38400/50000 (76.7%)]\tLoss: 0.001141\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47155/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8826/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.799 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 44 [0/50000 (0.0%)]\tLoss: 0.001216\n",
      "Train Epoch: 44 [12800/50000 (25.6%)]\tLoss: 0.001574\n",
      "Train Epoch: 44 [25600/50000 (51.2%)]\tLoss: 0.001497\n",
      "Train Epoch: 44 [38400/50000 (76.7%)]\tLoss: 0.002538\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47112/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8827/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.554 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 45 [0/50000 (0.0%)]\tLoss: 0.000667\n",
      "Train Epoch: 45 [12800/50000 (25.6%)]\tLoss: 0.000954\n",
      "Train Epoch: 45 [25600/50000 (51.2%)]\tLoss: 0.001410\n",
      "Train Epoch: 45 [38400/50000 (76.7%)]\tLoss: 0.001796\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47181/50000 (94.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8832/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.710 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 46 [0/50000 (0.0%)]\tLoss: 0.000892\n",
      "Train Epoch: 46 [12800/50000 (25.6%)]\tLoss: 0.000962\n",
      "Train Epoch: 46 [25600/50000 (51.2%)]\tLoss: 0.001330\n",
      "Train Epoch: 46 [38400/50000 (76.7%)]\tLoss: 0.001442\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47106/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8820/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.819 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 47 [0/50000 (0.0%)]\tLoss: 0.000982\n",
      "Train Epoch: 47 [12800/50000 (25.6%)]\tLoss: 0.000918\n",
      "Train Epoch: 47 [25600/50000 (51.2%)]\tLoss: 0.000918\n",
      "Train Epoch: 47 [38400/50000 (76.7%)]\tLoss: 0.001356\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47116/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8831/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.920 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 48 [0/50000 (0.0%)]\tLoss: 0.001128\n",
      "Train Epoch: 48 [12800/50000 (25.6%)]\tLoss: 0.001278\n",
      "Train Epoch: 48 [25600/50000 (51.2%)]\tLoss: 0.001609\n",
      "Train Epoch: 48 [38400/50000 (76.7%)]\tLoss: 0.002068\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47168/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8830/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.976 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 49 [0/50000 (0.0%)]\tLoss: 0.001236\n",
      "Train Epoch: 49 [12800/50000 (25.6%)]\tLoss: 0.001293\n",
      "Train Epoch: 49 [25600/50000 (51.2%)]\tLoss: 0.001934\n",
      "Train Epoch: 49 [38400/50000 (76.7%)]\tLoss: 0.000941\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47222/50000 (94.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8827/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.940 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 50 [0/50000 (0.0%)]\tLoss: 0.001787\n",
      "Train Epoch: 50 [12800/50000 (25.6%)]\tLoss: 0.001303\n",
      "Train Epoch: 50 [25600/50000 (51.2%)]\tLoss: 0.001137\n",
      "Train Epoch: 50 [38400/50000 (76.7%)]\tLoss: 0.001798\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47188/50000 (94.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8830/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.898 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 51 [0/50000 (0.0%)]\tLoss: 0.001082\n",
      "Train Epoch: 51 [12800/50000 (25.6%)]\tLoss: 0.001377\n",
      "Train Epoch: 51 [25600/50000 (51.2%)]\tLoss: 0.001441\n",
      "Train Epoch: 51 [38400/50000 (76.7%)]\tLoss: 0.001923\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47158/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8824/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.838 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 52 [0/50000 (0.0%)]\tLoss: 0.001112\n",
      "Train Epoch: 52 [12800/50000 (25.6%)]\tLoss: 0.001299\n",
      "Train Epoch: 52 [25600/50000 (51.2%)]\tLoss: 0.001295\n",
      "Train Epoch: 52 [38400/50000 (76.7%)]\tLoss: 0.001648\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47157/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8835/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.745 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 53 [0/50000 (0.0%)]\tLoss: 0.000950\n",
      "Train Epoch: 53 [12800/50000 (25.6%)]\tLoss: 0.001166\n",
      "Train Epoch: 53 [25600/50000 (51.2%)]\tLoss: 0.001103\n",
      "Train Epoch: 53 [38400/50000 (76.7%)]\tLoss: 0.001400\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47159/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8832/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.629 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 54 [0/50000 (0.0%)]\tLoss: 0.001246\n",
      "Train Epoch: 54 [12800/50000 (25.6%)]\tLoss: 0.000711\n",
      "Train Epoch: 54 [25600/50000 (51.2%)]\tLoss: 0.001246\n",
      "Train Epoch: 54 [38400/50000 (76.7%)]\tLoss: 0.001084\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47096/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8825/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.514 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 55 [0/50000 (0.0%)]\tLoss: 0.001392\n",
      "Train Epoch: 55 [12800/50000 (25.6%)]\tLoss: 0.001190\n",
      "Train Epoch: 55 [25600/50000 (51.2%)]\tLoss: 0.001122\n",
      "Train Epoch: 55 [38400/50000 (76.7%)]\tLoss: 0.001517\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47161/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8841/10000 (88.4%)\n",
      "\n",
      "One epoch time cost: 47.538 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 56 [0/50000 (0.0%)]\tLoss: 0.000940\n",
      "Train Epoch: 56 [12800/50000 (25.6%)]\tLoss: 0.001097\n",
      "Train Epoch: 56 [25600/50000 (51.2%)]\tLoss: 0.001471\n",
      "Train Epoch: 56 [38400/50000 (76.7%)]\tLoss: 0.001163\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47160/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8828/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.522 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 57 [0/50000 (0.0%)]\tLoss: 0.001365\n",
      "Train Epoch: 57 [12800/50000 (25.6%)]\tLoss: 0.000775\n",
      "Train Epoch: 57 [25600/50000 (51.2%)]\tLoss: 0.001643\n",
      "Train Epoch: 57 [38400/50000 (76.7%)]\tLoss: 0.001849\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47100/50000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8831/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.674 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 58 [0/50000 (0.0%)]\tLoss: 0.001776\n",
      "Train Epoch: 58 [12800/50000 (25.6%)]\tLoss: 0.000745\n",
      "Train Epoch: 58 [25600/50000 (51.2%)]\tLoss: 0.001635\n",
      "Train Epoch: 58 [38400/50000 (76.7%)]\tLoss: 0.001217\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47189/50000 (94.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8822/10000 (88.2%)\n",
      "\n",
      "One epoch time cost: 47.801 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Train Epoch: 59 [0/50000 (0.0%)]\tLoss: 0.001639\n",
      "Train Epoch: 59 [12800/50000 (25.6%)]\tLoss: 0.000827\n",
      "Train Epoch: 59 [25600/50000 (51.2%)]\tLoss: 0.001521\n",
      "Train Epoch: 59 [38400/50000 (76.7%)]\tLoss: 0.001146\n",
      "\n",
      "Training Set: Average loss: 0.0013,Accuracy: 47146/50000 (94.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8828/10000 (88.3%)\n",
      "\n",
      "One epoch time cost: 47.566 s \n",
      "\n",
      "----------------------------------------------- \n",
      "\n",
      "Best accuracy: tensor(0.8842)\n"
     ]
    }
   ],
   "source": [
    "best_prec1 = 0.\n",
    "\n",
    "import time\n",
    "\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "# training \n",
    "for epoch in range(0, 150):\n",
    "    if epoch in [50, 75]:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train(epoch,train_loss,train_acc)\n",
    "    prec1 = test(test_loss,test_acc)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    interval = end_time - start_time\n",
    "    print('One epoch time cost: {:.3f} s \\n'.format(interval))\n",
    "   \n",
    "    \n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, filepath='./checkpoint/baseline')\n",
    "    \n",
    "    print('----------------------------------------------- \\n')\n",
    "\n",
    "    \n",
    "print(\"Best accuracy: \"+str(best_prec1))\n",
    "\n",
    "# write loss data to txt file\n",
    "savepath = os.path.join('./checkpoint/baseline', \"baseline_train_loss.txt\")\n",
    "with open(savepath, \"w\") as fp:\n",
    "    for data in train_loss:\n",
    "        fp.write(str(data)+\"\\n\")\n",
    "    \n",
    "savepath = os.path.join('./checkpoint/baseline', \"baseline_train_acc.txt\")\n",
    "with open(savepath, \"w\") as fp:\n",
    "       for data in train_acc:\n",
    "        fp.write(str(data)+\"\\n\")\n",
    "    \n",
    "savepath = os.path.join('./checkpoint/baseline', \"baseline_test_loss.txt\")\n",
    "with open(savepath, \"w\") as fp:\n",
    "    for data in test_loss:\n",
    "        fp.write(str(data)+\"\\n\")\n",
    "    \n",
    "savepath = os.path.join('./checkpoint/baseline', \"baseline_test_acc.txt\")\n",
    "with open(savepath, \"w\") as fp:\n",
    "    for data in test_acc:\n",
    "        fp.write(str(data)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
