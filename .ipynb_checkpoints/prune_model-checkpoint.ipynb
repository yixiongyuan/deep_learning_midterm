{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cef64-da0d-4a72-b22c-81177e077ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is for pruning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbba266a-246a-4c86-af39-88387ebba67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import models\n",
    "from models import channel_selection\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6839efb-998d-483f-a346-a6fee020ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Slimming CIFAR prune')\n",
    "parser.add_argument('--dataset', type=str, default='cifar100',\n",
    "                    help='training dataset (default: cifar10)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=256, metavar='N',\n",
    "                    help='input batch size for testing (default: 256)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--depth', type=int, default=164,\n",
    "                    help='depth of the resnet')\n",
    "parser.add_argument('--percent', type=float, default=0.5,\n",
    "                    help='scale sparse rate (default: 0.5)')\n",
    "parser.add_argument('--model', default='', type=str, metavar='PATH',\n",
    "                    help='path to the model (default: none)')\n",
    "parser.add_argument('--save', default='', type=str, metavar='PATH',\n",
    "                    help='path to save pruned model (default: none)')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "if not os.path.exists(args.save):\n",
    "    os.makedirs(args.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28efdcfd-2ddf-4f88-a9e2-9314629b8164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "=> loading checkpoint './checkpoint/baseline.pth.tar'\n",
      "=> loaded checkpoint './checkpoint/baseline.pth.tar' (epoch 100) Prec1: 0.937600\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = models.resnet()\n",
    "\n",
    "# if device == 'cuda':\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "path = './checkpoint/baseline.pth.tar'\n",
    "print(\"=> loading checkpoint '{}'\".format(path))\n",
    "checkpoint = torch.load(path,map_location=device)\n",
    "\n",
    "start_epoch = checkpoint['epoch']\n",
    "#print(start_epoch)\n",
    "\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "#print(best_prec1)\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\".format(path, checkpoint['epoch'], best_prec1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d52d1e-d23d-496e-b221-100ff064182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "percent = 0.5 #eliminating channel ratio\n",
    "\n",
    "#count number of BN channels\n",
    "for name,m in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d) and 'BN' not in name:\n",
    "        total += m.weight.data.shape[0]\n",
    "\n",
    "# store weight value of BN layer\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for name,m in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d) and 'BN' not in name:\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "        index += size\n",
    "\n",
    "# sort all value\n",
    "y, i = torch.sort(bn)\n",
    "thre_index = int(total * percent)\n",
    "\n",
    "# pick the threshold\n",
    "thre = y[thre_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2573abb-2c1d-44e3-ab43-199d5de9f8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f89c3eb63d0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46b7b4a-c450-46d4-b4cf-4eb3abd572c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1993)\n"
     ]
    }
   ],
   "source": [
    "print(thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308d8ad8-889c-42dc-a6a0-736e714dac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer index: 80 \t total channel: 128 \t remaining channel: 111\n",
      "layer index: 83 \t total channel: 256 \t remaining channel: 132\n",
      "layer index: 89 \t total channel: 256 \t remaining channel: 70\n",
      "layer index: 92 \t total channel: 256 \t remaining channel: 167\n",
      "layer index: 97 \t total channel: 256 \t remaining channel: 80\n",
      "layer index: 100 \t total channel: 512 \t remaining channel: 263\n",
      "layer index: 106 \t total channel: 512 \t remaining channel: 32\n",
      "layer index: 109 \t total channel: 512 \t remaining channel: 222\n",
      "layer index: 112 \t total channel: 512 \t remaining channel: 490\n",
      "Pre-processing Successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pruned = 0\n",
    "cfg = []\n",
    "cfg_mask = []\n",
    "\n",
    "        \n",
    "for k, (name,m) in enumerate(model.named_modules()):\n",
    "    if isinstance(m, nn.BatchNorm2d)and 'fusion' not in name:\n",
    "        weight_copy = m.weight.data.abs().clone()\n",
    "        # if greater than threshold\n",
    "        mask = weight_copy.gt(thre).float().to(device)\n",
    "        \n",
    "        #count the number of channel been pruned\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "        \n",
    "        # set insignificant channel to 0\n",
    "        m.weight.data.mul_(mask)\n",
    "        m.bias.data.mul_(mask)\n",
    "        \n",
    "        # count the number of channel still in use\n",
    "        cfg.append(int(torch.sum(mask)))\n",
    "        cfg_mask.append(mask.clone())\n",
    "        \n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "        \n",
    "    elif isinstance(m, nn.MaxPool2d):\n",
    "        cfg.append('M')\n",
    "\n",
    "pruned_ratio = pruned/total\n",
    "\n",
    "print('Pre-processing Successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34cea506-a41b-485e-b65d-f26b6f10aa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Test set: Accuracy: 892/10000 (8.9%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# simple test model after Pre-processing prune (simple set BN scales to zeros)\n",
    "def test(model):\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_test)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))\n",
    "\n",
    "acc = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205aa773-ec74-4d43-a1ee-ba264104cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cfg:\n",
      "[111, 132, 70, 167, 80, 263, 32, 222, 490]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cfg:\")\n",
    "print(cfg)\n",
    "# print(\"cfg_mask\")\n",
    "# print(cfg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce93c5b7-65f1-47fa-a5b8-4b9c03cfb53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4196372\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newmodel = models.resnet(cfg=cfg)\n",
    "\n",
    "newmodel = newmodel.to(device)\n",
    "\n",
    "num_parameters = sum([param.nelement() for param in newmodel.parameters()])\n",
    "\n",
    "print(num_parameters)\n",
    "\n",
    "savepath = os.path.join('./checkpoint/', \"prune.txt\")\n",
    "with open(savepath, \"w\") as fp:\n",
    "    fp.write(\"Configuration: \\n\"+str(cfg)+\"\\n\")\n",
    "    fp.write(\"Number of parameters: \\n\"+str(num_parameters)+\"\\n\")\n",
    "    # fp.write(\"Test accuracy: \\n\"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50910b31-eb74-49c2-bf38-63ccebc82e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In shape: 111, Out shape 132.\n",
      "In shape: 132, Out shape 70.\n",
      "In shape: 70, Out shape 167.\n",
      "In shape: 167, Out shape 80.\n",
      "In shape: 80, Out shape 263.\n",
      "In shape: 263, Out shape 32.\n",
      "In shape: 32, Out shape 222.\n",
      "In shape: 222, Out shape 490.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (fusion_layer1): Sequential(\n",
      "    (0): FusionBlock(\n",
      "      (conv1): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): FusionBlock(\n",
      "      (conv1): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (multiscale): Sequential(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fusion_layer2): Sequential(\n",
      "    (0): FusionBlock(\n",
      "      (conv1): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
      "          (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): FusionBlock(\n",
      "      (conv1): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Sequential(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (multiscale): Sequential(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (basic_layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(111, 132, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(132, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(70, 167, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(167, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(167, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (basic_layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(80, 263, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(263, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(263, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(32, 222, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(222, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=490, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "old_modules = list(model.named_modules())\n",
    "new_modules = list(newmodel.named_modules())\n",
    "\n",
    "layer_id_in_cfg = 0\n",
    "\n",
    "start_mask = torch.ones(2)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "conv_count = 0\n",
    "\n",
    "for layer_id in range(len(old_modules)):\n",
    "    \n",
    "    name_0 = old_modules[layer_id][0]\n",
    "    m0 = old_modules[layer_id][1]\n",
    "    name_1 = new_modules[layer_id][0]\n",
    "    m1 = new_modules[layer_id][1]\n",
    "    \n",
    "    \n",
    "    if 'fusion' in name_0:\n",
    "        continue\n",
    "    \n",
    "    #bn layer\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        \n",
    "        # index of positive value\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "\n",
    "        if idx1.size == 1:\n",
    "            idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "        if isinstance(old_modules[layer_id + 1][1], channel_selection):\n",
    "            # If the next layer is the channel selection layer, \n",
    "            # then the current batchnorm 2d layer won't be pruned.\n",
    "            \n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            m1.running_mean = m0.running_mean.clone()\n",
    "            m1.running_var = m0.running_var.clone()\n",
    "\n",
    "            # We need to set the channel selection layer.\n",
    "            m2 = new_modules[layer_id + 1][1]\n",
    "            m2.indexes.data.zero_()\n",
    "            m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "\n",
    "            if layer_id_in_cfg < len(cfg_mask):\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "        else:\n",
    "            m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "            m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "            m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "            m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "\n",
    "            # do not change in Final FC\n",
    "            if layer_id_in_cfg < len(cfg_mask):  \n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "            \n",
    "# conv layer          \n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        if conv_count == 0:\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            conv_count += 1\n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id-1][1], channel_selection) or isinstance(old_modules[layer_id-1][1], nn.BatchNorm2d):\n",
    "            # This convers the convolutions in the residual block.\n",
    "            # The convolutions are either after the channel selection layer or after the batch normalization layer.\n",
    "            conv_count += 1\n",
    "            \n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            \n",
    "            print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "            \n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "                \n",
    "            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "\n",
    "            # If the current convolution is not the last convolution in the residual block, then we can change the \n",
    "            # number of output channels. Currently we use `conv_count` to detect whether it is such convolution.\n",
    "            if conv_count % 2 != 1:\n",
    "                w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "                \n",
    "            m1.weight.data = w1.clone()\n",
    "            continue\n",
    "\n",
    "        # We need to consider the case where there are downsampling convolutions. \n",
    "        # For these convolutions, we just copy the weights.\n",
    "        m1.weight.data = m0.weight.data.clone()\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        if idx0.size == 1:\n",
    "            idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "        m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "        m1.bias.data = m0.bias.data.clone()\n",
    "\n",
    "\n",
    "\n",
    "print(newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04212921-85d3-498f-a9bc-06600a6fbb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Test set: Accuracy: 892/10000 (8.9%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = newmodel\n",
    "test(model)\n",
    "\n",
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, os.path.join('./checkpoint/', 'pruned.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113627f-97af-4543-8788-d8da04b57fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
